"""Shared types for MCP Server v2 intelligent tools, middleware, and resources.

This module defines the data structures used by intelligent tools (Tier 3),
composed tools (Tier 2), interactive tools, and middleware components.

All types are defined as dataclasses for MCP protocol compatibility.
"""

from dataclasses import dataclass, field
from typing import Any, Literal

# ==============================================================================
# Core Result Types
# ==============================================================================


@dataclass
class AnalysisResult:
    """Result from an intelligent tool with AI synthesis.

    Intelligent tools (Tier 3) use sampling for synthesis but gracefully degrade
    to raw data when sampling is unavailable.

    Attributes:
        status: Execution status indicating whether synthesis was performed.
        findings: AI-synthesized findings when sampling is available.
        recommendations: Actionable recommendations derived from analysis.
        confidence: Confidence level in the analysis.
        raw_data: Underlying query results for transparency.
        analysis_hints: Manual analysis hints when sampling unavailable.

    Example:
        ```python
        result = AnalysisResult(
            status="success",
            findings={"key_insight": "Mobile users dropped 25%"},
            recommendations=["Investigate iOS crash reports"],
            confidence="high",
            raw_data={"baseline": 1000, "current": 750},
        )
        ```
    """

    status: Literal["success", "partial", "sampling_unavailable"]
    """Execution status: success (full synthesis), partial (some queries failed),
    or sampling_unavailable (client doesn't support sampling)."""

    findings: dict[str, Any] | None = None
    """AI-synthesized findings when sampling is available."""

    recommendations: list[str] = field(default_factory=list)
    """Actionable recommendations derived from analysis."""

    confidence: Literal["low", "medium", "high"] | None = None
    """Confidence level in the analysis."""

    raw_data: dict[str, Any] = field(default_factory=dict)
    """Underlying query results for transparency."""

    analysis_hints: list[str] = field(default_factory=list)
    """Manual analysis hints when sampling unavailable."""


# ==============================================================================
# Execution Plan Types (for ask_mixpanel)
# ==============================================================================


@dataclass
class QuerySpec:
    """Specification for a single query to execute.

    Used by ExecutionPlan to describe individual queries that answer
    a natural language question.

    Attributes:
        method: The Workspace method to call.
        params: Parameters to pass to the method.

    Example:
        ```python
        query = QuerySpec(
            method="segmentation",
            params={"event": "login", "from_date": "2026-01-01"},
        )
        ```
    """

    method: Literal[
        "segmentation",
        "retention",
        "funnel",
        "property_counts",
        "event_counts",
        "activity_feed",
        "jql",
    ]
    """The Workspace method to call."""

    params: dict[str, Any] = field(default_factory=dict)
    """Parameters to pass to the method."""


@dataclass
class ExecutionPlan:
    """Plan for answering a natural language question.

    Generated by ask_mixpanel to translate natural language queries
    into executable Workspace method calls.

    Attributes:
        intent: Brief description of user's analytical intent.
        query_type: Primary analysis type (retention, conversion, trend, etc.).
        queries: List of queries to execute.
        date_range: Date range for all queries.
        comparison_needed: Whether comparison between periods/segments is required.
        reasoning: Explanation of why these queries answer the question.

    Example:
        ```python
        plan = ExecutionPlan(
            intent="Analyze user retention after signup",
            query_type="retention",
            queries=[QuerySpec(method="retention", params={...})],
            date_range={"from_date": "2026-01-01", "to_date": "2026-01-31"},
            comparison_needed=False,
            reasoning="Retention analysis shows return rate after signup",
        )
        ```
    """

    intent: str
    """Brief description of user's analytical intent."""

    query_type: str
    """Primary analysis type (retention, conversion, trend, etc.)."""

    queries: list[QuerySpec]
    """List of queries to execute."""

    date_range: dict[str, str]
    """Date range for all queries: {from_date, to_date}."""

    comparison_needed: bool = False
    """Whether comparison between periods/segments is required."""

    reasoning: str = ""
    """Explanation of why these queries answer the question."""


# ==============================================================================
# Diagnosis Types (for diagnose_metric_drop)
# ==============================================================================


@dataclass
class SegmentContribution:
    """A segment's contribution to a metric change.

    Used by DiagnosisResult to describe which segments are driving
    a metric drop or increase.

    Attributes:
        dimension: Property dimension (e.g., 'platform', 'country').
        segment: Specific segment value (e.g., 'iOS', 'US').
        contribution_pct: Percentage of total drop attributable to this segment.
        baseline_value: Value during baseline period.
        current_value: Value during drop period.
        description: Human-readable description of the impact.

    Example:
        ```python
        contribution = SegmentContribution(
            dimension="platform",
            segment="iOS",
            contribution_pct=65.0,
            baseline_value=1000,
            current_value=650,
            description="iOS users dropped by 35%, accounting for 65% of total drop",
        )
        ```
    """

    dimension: str
    """Property dimension (e.g., 'platform', 'country')."""

    segment: str
    """Specific segment value (e.g., 'iOS', 'US')."""

    contribution_pct: float
    """Percentage of total drop attributable to this segment."""

    baseline_value: float
    """Value during baseline period."""

    current_value: float
    """Value during drop period."""

    description: str
    """Human-readable description of the impact."""


@dataclass
class DiagnosisResult:
    """Result from diagnose_metric_drop tool.

    Provides structured analysis of a metric drop including primary driver,
    secondary factors, and recommendations.

    Attributes:
        drop_confirmed: Whether a significant drop was detected.
        drop_percentage: Percentage change from baseline to drop period.
        primary_driver: Main segment contributing to the drop.
        secondary_factors: Other contributing segments.
        recommendations: Actionable next steps.
        confidence: Confidence in the diagnosis.
        caveats: Data quality concerns or limitations.
        raw_data: Underlying query results.

    Example:
        ```python
        result = DiagnosisResult(
            drop_confirmed=True,
            drop_percentage=-25.0,
            primary_driver=SegmentContribution(...),
            recommendations=["Check iOS app store reviews"],
            confidence="high",
        )
        ```
    """

    drop_confirmed: bool
    """Whether a significant drop was detected."""

    drop_percentage: float
    """Percentage change from baseline to drop period."""

    primary_driver: SegmentContribution | None = None
    """Main segment contributing to the drop."""

    secondary_factors: list[SegmentContribution] = field(default_factory=list)
    """Other contributing segments."""

    recommendations: list[str] = field(default_factory=list)
    """Actionable next steps."""

    confidence: Literal["low", "medium", "high"] = "medium"
    """Confidence in the diagnosis."""

    caveats: list[str] = field(default_factory=list)
    """Data quality concerns or limitations."""

    raw_data: dict[str, Any] = field(default_factory=dict)
    """Underlying query results."""


# ==============================================================================
# Funnel Optimization Types
# ==============================================================================


@dataclass
class OptimizationRecommendation:
    """A single optimization recommendation.

    Used by FunnelOptimizationResult to provide actionable advice.

    Attributes:
        action: What to do.
        priority: Priority level.
        expected_impact: Expected improvement if implemented.

    Example:
        ```python
        rec = OptimizationRecommendation(
            action="Add progress indicator on checkout step",
            priority="high",
            expected_impact="Could improve step 3 conversion by 10-15%",
        )
        ```
    """

    action: str
    """What to do."""

    priority: Literal["high", "medium", "low"]
    """Priority level."""

    expected_impact: str
    """Expected improvement if implemented."""


@dataclass
class FunnelOptimizationResult:
    """Result from funnel_optimization_report tool.

    Provides comprehensive funnel analysis with bottleneck identification
    and optimization recommendations.

    Attributes:
        executive_summary: 2-3 sentence summary of key findings.
        overall_conversion_rate: End-to-end conversion rate.
        bottleneck: Details of worst-performing step.
        top_performing_segments: Segments with highest conversion.
        underperforming_segments: Segments with lowest conversion.
        recommendations: Prioritized optimization actions.
        raw_data: Underlying funnel and segment data.

    Example:
        ```python
        result = FunnelOptimizationResult(
            executive_summary="Checkout funnel converts at 12%. Step 3 is bottleneck.",
            overall_conversion_rate=0.12,
            bottleneck={"step_number": 3, "step_name": "Payment", "drop_pct": 45},
            recommendations=[OptimizationRecommendation(...)],
        )
        ```
    """

    executive_summary: str
    """2-3 sentence summary of key findings."""

    overall_conversion_rate: float
    """End-to-end conversion rate."""

    bottleneck: dict[str, Any]
    """Details of worst-performing step: {step_number, step_name, drop_percentage}."""

    top_performing_segments: list[dict[str, Any]] = field(default_factory=list)
    """Segments with highest conversion."""

    underperforming_segments: list[dict[str, Any]] = field(default_factory=list)
    """Segments with lowest conversion."""

    recommendations: list[OptimizationRecommendation] = field(default_factory=list)
    """Prioritized optimization actions."""

    raw_data: dict[str, Any] = field(default_factory=dict)
    """Underlying funnel and segment data."""


# ==============================================================================
# Dashboard Types
# ==============================================================================


@dataclass
class AARRRMetrics:
    """Metrics for one AARRR category.

    Used by ProductHealthDashboard to represent metrics for each
    pirate metrics category.

    Attributes:
        category: AARRR category.
        primary_metric: Main metric value for this category.
        trend: Time series data as {date: value}.
        by_segment: Breakdown by segment if available.

    Example:
        ```python
        metrics = AARRRMetrics(
            category="retention",
            primary_metric=0.35,
            trend={"2026-01-01": 0.32, "2026-01-08": 0.35},
        )
        ```
    """

    category: Literal["acquisition", "activation", "retention", "revenue", "referral"]
    """AARRR category."""

    primary_metric: float
    """Main metric value for this category."""

    trend: dict[str, float] = field(default_factory=dict)
    """Time series data: {date: value}."""

    by_segment: dict[str, dict[str, Any]] | None = None
    """Breakdown by segment if available."""


@dataclass
class ProductHealthDashboard:
    """Complete AARRR product health dashboard.

    Result from product_health_dashboard tool providing comprehensive
    pirate metrics analysis.

    Attributes:
        period: Analysis period as {from_date, to_date}.
        acquisition: Acquisition metrics (signups, traffic).
        activation: Activation metrics (onboarding, first value).
        retention: Retention metrics (D1/D7/D30 return rates).
        revenue: Revenue metrics (transactions, ARPU).
        referral: Referral metrics (invites, viral coefficient).
        health_score: Score 1-10 for each category.

    Example:
        ```python
        dashboard = ProductHealthDashboard(
            period={"from_date": "2026-01-01", "to_date": "2026-01-31"},
            acquisition=AARRRMetrics(category="acquisition", primary_metric=1000),
            retention=AARRRMetrics(category="retention", primary_metric=0.35),
            health_score={"acquisition": 8, "retention": 6},
        )
        ```
    """

    period: dict[str, str]
    """Analysis period: {from_date, to_date}."""

    acquisition: AARRRMetrics | None = None
    """Acquisition metrics (signups, traffic)."""

    activation: AARRRMetrics | None = None
    """Activation metrics (onboarding, first value)."""

    retention: AARRRMetrics | None = None
    """Retention metrics (D1/D7/D30 return rates)."""

    revenue: AARRRMetrics | None = None
    """Revenue metrics (transactions, ARPU)."""

    referral: AARRRMetrics | None = None
    """Referral metrics (invites, viral coefficient)."""

    health_score: dict[str, int] | None = None
    """Score 1-10 for each category."""


# ==============================================================================
# Investigation Types
# ==============================================================================


@dataclass
class QuestionFinding:
    """Finding for a single GQM question.

    Used by GQMInvestigation to report results for each sub-question.

    Attributes:
        question: The operational question.
        query_type: Type of query used.
        status: Whether query succeeded.
        result: Query result if successful.
        error: Error message if failed.

    Example:
        ```python
        finding = QuestionFinding(
            question="What is the day-7 retention rate?",
            query_type="retention",
            status="success",
            result={"d7_retention": 0.35},
        )
        ```
    """

    question: str
    """The operational question."""

    query_type: str
    """Type of query used."""

    status: Literal["success", "failed"]
    """Whether query succeeded."""

    result: dict[str, Any] | None = None
    """Query result if successful."""

    error: str | None = None
    """Error message if failed."""


@dataclass
class GQMInvestigation:
    """Result from gqm_investigation tool.

    Provides structured investigation using Goal-Question-Metric methodology.

    Attributes:
        interpreted_goal: Clarified version of user's goal.
        aarrr_category: Classification for scoping.
        period: Analysis period.
        schema_context: Available events and funnels used.
        questions: List of sub-questions generated.
        findings: Results for each question.
        synthesis: Overall synthesis of findings.
        next_steps: Suggested follow-up investigations.

    Example:
        ```python
        investigation = GQMInvestigation(
            interpreted_goal="Understand why retention is declining",
            aarrr_category="retention",
            period={"from_date": "2026-01-01", "to_date": "2026-01-31"},
            questions=[{"question": "What is current D7 retention?", ...}],
            findings=[QuestionFinding(...)],
            synthesis={"key_insight": "Retention dropped after v2.0 release"},
            next_steps=["Investigate v2.0 release impact"],
        )
        ```
    """

    interpreted_goal: str
    """Clarified version of user's goal."""

    aarrr_category: Literal[
        "acquisition", "activation", "retention", "revenue", "referral"
    ]
    """Classification for scoping."""

    period: dict[str, str]
    """Analysis period: {from_date, to_date}."""

    schema_context: dict[str, Any] = field(default_factory=dict)
    """Available events and funnels used."""

    questions: list[dict[str, str]] = field(default_factory=list)
    """List of sub-questions generated."""

    findings: list[QuestionFinding] = field(default_factory=list)
    """Results for each question."""

    synthesis: dict[str, Any] = field(default_factory=dict)
    """Overall synthesis of findings."""

    next_steps: list[str] = field(default_factory=list)
    """Suggested follow-up investigations."""


# ==============================================================================
# Cohort Comparison Types
# ==============================================================================


@dataclass
class CohortMetrics:
    """Metrics for a single cohort.

    Used by CohortComparison to represent one of the cohorts being compared.

    Attributes:
        name: Cohort display name.
        filter: Filter expression defining the cohort.
        user_count: Number of users in cohort.
        metrics: Computed metrics for this cohort.

    Example:
        ```python
        cohort = CohortMetrics(
            name="Power Users",
            filter='properties["sessions"] >= 10',
            user_count=5000,
            metrics={"retention_d7": 0.65, "events_per_user": 25},
        )
        ```
    """

    name: str
    """Cohort display name."""

    filter: str
    """Filter expression defining the cohort."""

    user_count: int | None = None
    """Number of users in cohort."""

    metrics: dict[str, Any] = field(default_factory=dict)
    """Computed metrics for this cohort."""


@dataclass
class CohortComparison:
    """Result from cohort_comparison tool.

    Provides comparative analysis of two user cohorts across behavioral dimensions.

    Attributes:
        cohort_a: First cohort.
        cohort_b: Second cohort.
        period: Analysis period.
        comparisons: Comparison results by dimension.
        statistical_significance: Whether differences are statistically significant.

    Example:
        ```python
        comparison = CohortComparison(
            cohort_a=CohortMetrics(name="Power Users", ...),
            cohort_b=CohortMetrics(name="Casual Users", ...),
            period={"from_date": "2026-01-01", "to_date": "2026-01-31"},
            comparisons={"retention": {...}, "event_frequency": {...}},
        )
        ```
    """

    cohort_a: CohortMetrics
    """First cohort."""

    cohort_b: CohortMetrics
    """Second cohort."""

    period: dict[str, str]
    """Analysis period."""

    comparisons: dict[str, dict[str, Any]] = field(default_factory=dict)
    """Comparison results by dimension (retention, event_frequency, top_events)."""

    statistical_significance: dict[str, bool] | None = None
    """Whether differences are statistically significant."""


# ==============================================================================
# Elicitation Types
# ==============================================================================


@dataclass
class FetchConfirmation:
    """User confirmation for large fetch operation.

    Response type for safe_large_fetch elicitation.

    Attributes:
        proceed: Whether to proceed with the fetch.
        reduce_scope: Whether to reduce the scope.
        new_limit: New event limit if reducing scope.

    Example:
        ```python
        confirmation = FetchConfirmation(
            proceed=True,
            reduce_scope=True,
            new_limit=50000,
        )
        ```
    """

    proceed: bool
    """Whether to proceed with the fetch."""

    reduce_scope: bool = False
    """Whether to reduce the scope."""

    new_limit: int | None = None
    """New event limit if reducing scope."""


@dataclass
class AnalysisChoice:
    """User's choice for analysis direction.

    Response type for guided_analysis focus selection.

    Attributes:
        focus_area: Primary focus area.
        time_period: Analysis time period.
        custom_start: Custom start date if time_period is 'custom'.
        custom_end: Custom end date if time_period is 'custom'.

    Example:
        ```python
        choice = AnalysisChoice(
            focus_area="retention",
            time_period="last_30_days",
        )
        ```
    """

    focus_area: Literal["conversion", "retention", "engagement", "revenue"]
    """Primary focus area."""

    time_period: Literal["last_7_days", "last_30_days", "last_90_days", "custom"]
    """Analysis time period."""

    custom_start: str | None = None
    """Custom start date if time_period is 'custom'."""

    custom_end: str | None = None
    """Custom end date if time_period is 'custom'."""


@dataclass
class SegmentChoice:
    """User's choice for segment investigation.

    Response type for guided_analysis segment selection.

    Attributes:
        segment_index: Index of selected segment from presented list.
        investigate_further: Whether to drill deeper into this segment.

    Example:
        ```python
        choice = SegmentChoice(
            segment_index=2,
            investigate_further=True,
        )
        ```
    """

    segment_index: int
    """Index of selected segment from presented list."""

    investigate_further: bool = True
    """Whether to drill deeper into this segment."""


# ==============================================================================
# Middleware Types
# ==============================================================================


@dataclass
class RateLimitState:
    """State tracking for rate limiting.

    Internal state for managing rate limiting middleware.

    Attributes:
        request_times: Timestamps of recent requests.
        active_count: Number of currently active requests.

    Example:
        ```python
        state = RateLimitState(
            request_times=[1704067200.0, 1704067201.0],
            active_count=2,
        )
        ```
    """

    request_times: list[float] = field(default_factory=list)
    """Timestamps of recent requests."""

    active_count: int = 0
    """Number of currently active requests."""


@dataclass
class MixpanelRateLimits:
    """Mixpanel API rate limit configuration.

    Configuration for different Mixpanel API rate limits.

    Attributes:
        query_hourly_limit: Query API hourly limit.
        query_concurrent_limit: Query API concurrent request limit.
        export_hourly_limit: Export API hourly limit.
        export_per_second_limit: Export API per-second limit.
        export_concurrent_limit: Export API concurrent request limit.

    Example:
        ```python
        limits = MixpanelRateLimits(
            query_hourly_limit=60,
            query_concurrent_limit=5,
        )
        ```
    """

    query_hourly_limit: int = 60
    """Query API hourly limit."""

    query_concurrent_limit: int = 5
    """Query API concurrent request limit."""

    export_hourly_limit: int = 60
    """Export API hourly limit."""

    export_per_second_limit: int = 3
    """Export API per-second limit."""

    export_concurrent_limit: int = 100
    """Export API concurrent request limit."""


@dataclass
class CacheEntry:
    """Cached response entry.

    Internal structure for storing cached tool responses.

    Attributes:
        key: Cache key (hash of tool name + arguments).
        value: Cached result.
        created_at: Timestamp when cached.
        ttl: Time-to-live in seconds.

    Example:
        ```python
        entry = CacheEntry(
            key="list_events:abc123",
            value=["login", "signup", "purchase"],
            created_at=1704067200.0,
            ttl=300,
        )
        assert not entry.is_expired
        ```
    """

    key: str
    """Cache key (hash of tool name + arguments)."""

    value: Any
    """Cached result."""

    created_at: float
    """Timestamp when cached."""

    ttl: int
    """Time-to-live in seconds."""

    @property
    def is_expired(self) -> bool:
        """Check if cache entry has expired.

        Returns:
            True if the entry has exceeded its TTL, False otherwise.
        """
        import time

        return time.time() - self.created_at > self.ttl
